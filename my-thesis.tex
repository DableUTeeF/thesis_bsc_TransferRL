\documentclass[12pt,a4paper]{article}
\usepackage{makeidx}
\makeindex

\usepackage{setspace}
\usepackage{fancyhdr}

\usepackage{tabto}
\usepackage{xltxtra}
\usepackage{polyglossia}
\usepackage[top=25mm, bottom=20mm, left=25mm, right=20mm]{geometry}
\XeTeXlinebreaklocale "th"
\XeTeXlinebreakskip = 0pt plus 1pt
\defaultfontfeatures{Scale=1.23}
\title{Transferable Reinforcement Learning for Board Games}
\author{Natthaphon Hongcharoen}
%% ใช้ร่วมกับ polyglossia เพื่อให้ได้วันที่ภาษาไทย
\setdefaultlanguage{english}
\newfontfamily{\thaifont}[Script=Thai]{TH SarabunPSK}

\begin{document}
\fontspec[
ItalicFont={TH SarabunPSK Italic},
BoldFont={TH SarabunPSK Bold},
BoldItalicFont={TH SarabunPSK Bold Italic},
]{TH SarabunPSK}

\begin{titlepage}
	\centering
	\includegraphics[width=0.15\textwidth]{logo.png}\par\vspace{1cm}
	{\scshape\Huge Transferable Reinforcement Learning for \par Board Games\par}
	\vfill
	{\Large\itshape Natthaphon Hongcharoen\par}
	\vfill
	{\Large  \par}
	{\large Thesis presented for Faculty of Engineering and Technology \par\vspace{0.1cm}}
	{\large Panyapiwat Insitute of Management\par\vspace{0.1cm}}
	{\large In study of bachelor of science, Computer Engineering
	}

	%\vfill

	% Bottom of the page
	{\large Study year 2018 \par}
\end{titlepage}

\clearpage % End title page
\pagestyle{empty}  % No headers or footers for the following pages

\section*{Abstract}
\tab The modern Reinforcement Learning has become widely interested recently, after the AlphaGo\cite{AlphaGo} became the first program to defeat a world champion in the game of Go. And by 2017, the AlphaGoZero\cite{AlphaGoZero} and AlphaZero\cite{AlphaZero} programs achieved superhuman performance in the game of Go and Chess, by solely trained from games of self-play which require no human knowledge. But in contrast, both AlphaGoZero and AlphaZero required extremely powerful processor as they need to random move in the early state of training which cost more expend. While in Computer Vision domain, we often use pretrained model from large dataset such as Imagenet\cite{Imagenet} and retrain it for desired task which cost less time and achieved more accuracy than train it from scratch. In this thesis, we experiment a method to reuse the trained model of a game such as Othello, Connect4 or Gomoku and re-training with one different game by hoping it to be faster.
\clearpage

\section*{Chapter 1: Introduction}
{\large 1.1 Background \par\vspace{0.1cm}}
{
The modern Reinforcement Learning such as AlphaGo has showed outstanding performance by won against world champion in game of Go a decade earlier than predicted\cite{GovsCom}[18]. And the AlphaGoZero has showed that it possible to train Reinforcement Learning without any human knowledge while still achieved good performance\cite{AlphaGoZero}\cite{AlphaZero}. In contrast of good result, for AlphaGo, by using ‘supervised learning from human expert games’\cite{AlphaGo} means it's require the expert games that might be difficult to obtained or inthe worst case, it might be impossible to get. And in case of AlphaGoZero, according to original paper\cite{AlphaGoZero}, the model need to be trained with 29 million games of self-play. Parameters were updated from 3.1 million mini-batches of 2,048 positions each. In Gian-Carlo Pascutto's experiments, every 2000 self-play moves generated by GTX-1080ti GPU would take 93 seconds, which means it need 1700 years to play all 29 million games\cite{GCP}. It practically impossible to train AlphaGoZero in personal level.\par
}
{
Meanwhile in Computer Vision domain, the Transferring weights which pretrained in large datasets is widely used as there are ImageNet\cite{Imagenet} pretrained weights in many popular libraries[15][16][17] because of it often improve regularizing and better performance and need less sample to train[14]. In the same way, Reinforcement Learning algorithm should be able to transferring features which makes training process faster.
}
\clearpage
\bibliographystyle{acm}
\bibliography{testBibXeTex}

\end{document}
